time: 172800
nodes: 2
procs: 40
account string: lp_polymer_goa_project
queue: q72h
========================================================================
GROMACS:    gmx grompp, VERSION 5.0.4

GROMACS is written by:
Emile Apol         Rossen Apostolov   Herman J.C. Berendsen Par Bjelkmar       
Aldert van Buuren  Rudi van Drunen    Anton Feenstra     Sebastian Fritsch  
Gerrit Groenhof    Christoph Junghans Peter Kasson       Carsten Kutzner    
Per Larsson        Justin A. Lemkul   Magnus Lundborg    Pieter Meulenhoff  
Erik Marklund      Teemu Murtola      Szilard Pall       Sander Pronk       
Roland Schulz      Alexey Shvetsov    Michael Shirts     Alfons Sijbers     
Peter Tieleman     Christian Wennberg Maarten Wolf       
and the project leaders:
Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2014, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx grompp, VERSION 5.0.4
Executable:   /apps/leuven/thinking/2014a/software/GROMACS/5.0.4-intel-2014a-hybrid/bin/gmx_mpi
Library dir:  /apps/leuven/thinking/2014a/software/GROMACS/5.0.4-intel-2014a-hybrid/share/gromacs/top
Command line:
  grompp_mpi -v

Ignoring obsolete mdp entry 'domain-decomposition'
Ignoring obsolete mdp entry 'optimize-fft'
Replacing old mdp entry 'unconstrained-start' by 'continuation'
Replacing old mdp entry 'nstxtcout' by 'nstxout-compressed'
Replacing old mdp entry 'xtc-grps' by 'compressed-x-grps'
Replacing old mdp entry 'xtc-precision' by 'compressed-x-precision'

Back Off! I just backed up mdout.mdp to ./#mdout.mdp.3#
checking input for internal consistency...

NOTE 1 [file grompp.mdp]:
  nstcomm < nstcalcenergy defeats the purpose of nstcalcenergy, setting
  nstcomm to nstcalcenergy

Setting the LD random seed to 2920542075
processing topology...
Generated 331705 of the 331705 non-bonded parameter combinations
Generating 1-4 interactions: fudge = 0.5
Generated 331705 of the 331705 1-4 parameter combinations
Excluding 3 bonded neighbours molecule type 'MEL'
turning H bonds into constraints...
Excluding 2 bonded neighbours molecule type 'WAT'
turning H bonds into constraints...
processing coordinates...
double-checking input for internal consistency...
Velocities were taken from a Maxwell distribution at 468 K
Removing all charge groups because cutoff-scheme=Verlet
renumbering atomtypes...
converting bonded parameters...
initialising group options...
processing index file...
Analysing residue names:
There are:   500      Other residues
There are:  1500      Water residues
Analysing residues not classified as Protein/DNA/RNA/Water and splitting into groups...
Making dummy/rest group for Acceleration containing 18000 elements
Making dummy/rest group for Freeze containing 18000 elements
Making dummy/rest group for VCM containing 18000 elements
Number of degrees of freedom in T-Coupling group System is 43497.00
Making dummy/rest group for User1 containing 18000 elements
Making dummy/rest group for User2 containing 18000 elements
Making dummy/rest group for Or. Res. Fit containing 18000 elements
Making dummy/rest group for QMMM containing 18000 elements
T-Coupling       has 1 element(s): System
Energy Mon.      has 1 element(s): System
Acceleration     has 1 element(s): rest
Freeze           has 1 element(s): rest
User1            has 1 element(s): rest
User2            has 1 element(s): rest
VCM              has 1 element(s): rest
Compressed X     has 1 element(s): System
Or. Res. Fit     has 1 element(s): rest
QMMM             has 1 element(s): rest
Determining Verlet buffer for a tolerance of 0.005 kJ/mol/ps at 468 K
Calculated rlist for 1x1 atom pair-list as 1.200 nm, buffer size 0.000 nm
Set rlist, assuming 4x4 atom pair-list, to 1.200 nm, buffer size 0.000 nm
Checking consistency between energy and charge groups...
Calculating fourier grid dimensions for X Y Z
Using a fourier grid of 128x128x128, spacing 0.119 0.119 0.119
Estimate for the relative computational load of the PME mesh part: 0.82

NOTE 2 [file grompp.mdp]:
  The optimal PME mesh load for parallel simulations is below 0.5
  and for highly parallel simulations between 0.25 and 0.33,
  for higher performance, increase the cut-off and the PME grid spacing.


This run will generate roughly 106 Mb of data
writing run input file...

There were 2 notes

Back Off! I just backed up topol.tpr to ./#topol.tpr.3#

gcq#373: "If humanity has fled shivering from the starry spaces, it has become minutely at home in the interstices of the speck that it inhabits for an instant" (George H. Mead)

running mpdallexit on r2i1n4
LAUNCHED mpd on r2i1n4  via  
RUNNING: mpd on r2i1n4
LAUNCHED mpd on r2i1n14  via  r2i1n4
RUNNING: mpd on r2i1n14
GROMACS:    gmx mdrun, VERSION 5.0.4

GROMACS is written by:
Emile Apol         Rossen Apostolov   Herman J.C. Berendsen Par Bjelkmar       
Aldert van Buuren  Rudi van Drunen    Anton Feenstra     Sebastian Fritsch  
Gerrit Groenhof    Christoph Junghans Peter Kasson       Carsten Kutzner    
Per Larsson        Justin A. Lemkul   Magnus Lundborg    Pieter Meulenhoff  
Erik Marklund      Teemu Murtola      Szilard Pall       Sander Pronk       
Roland Schulz      Alexey Shvetsov    Michael Shirts     Alfons Sijbers     
Peter Tieleman     Christian Wennberg Maarten Wolf       
and the project leaders:
Mark Abraham, Berk Hess, Erik Lindahl, and David van der Spoel

Copyright (c) 1991-2000, University of Groningen, The Netherlands.
Copyright (c) 2001-2014, The GROMACS development team at
Uppsala University, Stockholm University and
the Royal Institute of Technology, Sweden.
check out http://www.gromacs.org for more information.

GROMACS is free software; you can redistribute it and/or modify it
under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation; either version 2.1
of the License, or (at your option) any later version.

GROMACS:      gmx mdrun, VERSION 5.0.4
Executable:   /apps/leuven/thinking/2014a/software/GROMACS/5.0.4-intel-2014a-hybrid/bin/gmx_mpi
Library dir:  /apps/leuven/thinking/2014a/software/GROMACS/5.0.4-intel-2014a-hybrid/share/gromacs/top
Command line:
  mdrun_mpi


Back Off! I just backed up md.log to ./#md.log.1#

Number of hardware threads detected (20) does not match the number reported by OpenMP (1).
Consider setting the launch configuration manually!
Reading file topol.tpr, VERSION 5.0.4 (single precision)
Changing nstlist from 15 to 40, rlist from 1.2 to 1.2

Using 40 MPI processes
Using 1 OpenMP thread per MPI process

Non-default thread affinity set probably by the OpenMP library,
disabling internal thread affinity

Back Off! I just backed up traj_comp.xtc to ./#traj_comp.xtc.1#

Back Off! I just backed up ener.edr to ./#ener.edr.1#
starting mdrun 'MKTOP'
5000000 steps,   5000.0 ps.

NOTE: Turning on dynamic load balancing


Writing final coordinates.

 Average load imbalance: 81.8 %
 Part of the total run time spent waiting due to load imbalance: 12.0 %
 Steps where the load balancing was limited by -rdd, -rcon and/or -dds: X 1 % Y 2 % Z 0 %

NOTE: 12.0 % of the available CPU time was lost due to load imbalance
      in the domain decomposition.


               Core t (s)   Wall t (s)        (%)
       Time:   922757.954    23071.245     3999.6
                         6h24:31
                 (ns/day)    (hour/ns)
Performance:       18.725        1.282

gcq#202: "It's Bicycle Repair Man !" (Monty Python)

========================================================================
Epilogue args:
Date: Sat Dec  5 21:50:30 CET 2015
Allocated nodes:
r2i1n4
r2i1n4
r2i1n4
r2i1n4
r2i1n4
r2i1n4
r2i1n4
r2i1n4
r2i1n4
r2i1n4
r2i1n4
r2i1n4
r2i1n4
r2i1n4
r2i1n4
r2i1n4
r2i1n4
r2i1n4
r2i1n4
r2i1n4
r2i1n14
r2i1n14
r2i1n14
r2i1n14
r2i1n14
r2i1n14
r2i1n14
r2i1n14
r2i1n14
r2i1n14
r2i1n14
r2i1n14
r2i1n14
r2i1n14
r2i1n14
r2i1n14
r2i1n14
r2i1n14
r2i1n14
r2i1n14
Job ID: 20228639.icts-p-svcs-1
User ID: vsc30783
Group ID: vsc30783
Job Name: MELF_NPT_468
Session ID: 61473
Resource List: neednodes=2:ppn=20,nodes=2:ppn=20,pmem=1gb,walltime=48:00:00
Resources Used: cput=00:00:01,mem=17092kb,vmem=462240kb,walltime=06:24:35
Queue Name: q72h
Account String: lp_polymer_goa_project
-------------------------------------------------------------------------
time: 23075
nodes: 2
procs: 40
account: lp_polymer_goa_project
